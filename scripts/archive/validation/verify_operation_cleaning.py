"""
éªŒè¯MESå·¥åºæ¸…æ´—åŠŸèƒ½
ä½¿ç”¨CSVæ–‡ä»¶éªŒè¯æ¸…æ´—æ•ˆæœï¼Œç”Ÿæˆæ¸…æ´—æŠ¥å‘Š
"""

import pandas as pd
import sys
import os
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥etl_dataclean_mes_batch_report
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from etl_dataclean_mes_batch_report import standardize_operation_name

def generate_cleaning_report():
    """ç”Ÿæˆå·¥åºæ¸…æ´—æŠ¥å‘Š"""
    
    print("ğŸ“Š MESå·¥åºåç§°æ¸…æ´—éªŒè¯æŠ¥å‘Š")
    print("=" * 80)
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # è¯»å–CSVæ•°æ®
    data_path = r"c:\Users\huangk14\OneDrive - Medtronic PLC\Huangkai Files\B1_Project\250418_MDDAP_project\10-SAæŒ‡æ ‡\11æ•°æ®æ¨¡æ¿\Product Output -CZM -FY26.csv"
    
    try:
        df = pd.read_csv(data_path, low_memory=False)
        print(f"âœ“ æˆåŠŸè¯»å–æ•°æ®æ–‡ä»¶: {os.path.basename(data_path)}")
        print(f"ğŸ“‹ æ•°æ®è§„æ¨¡: {len(df):,} æ¡è®°å½•")
        
        if 'Step_Name' not in df.columns:
            print("âŒ æœªæ‰¾åˆ°Step_Nameåˆ—")
            return
            
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
        return
    
    print()
    
    # åº”ç”¨æ¸…æ´—å‡½æ•°
    print("ğŸ§¹ åº”ç”¨å·¥åºæ¸…æ´—è§„åˆ™...")
    df['Cleaned_Operation'] = df['Step_Name'].apply(standardize_operation_name)
    
    # ç»Ÿè®¡æ¸…æ´—å‰åçš„å·¥åºæ•°é‡
    original_count = df['Step_Name'].nunique()
    cleaned_count = df['Cleaned_Operation'].nunique()
    
    print(f"ğŸ“ˆ æ¸…æ´—æ•ˆæœç»Ÿè®¡:")
    print(f"   åŸå§‹å·¥åºæ•°é‡: {original_count} ä¸ª")
    print(f"   æ¸…æ´—åå·¥åºæ•°é‡: {cleaned_count} ä¸ª")
    print(f"   å‡å°‘å·¥åºæ•°é‡: {original_count - cleaned_count} ä¸ª")
    print(f"   å‡å°‘æ¯”ä¾‹: {((original_count - cleaned_count) / original_count * 100):.1f}%")
    print()
    
    # æ˜¾ç¤ºæ¸…æ´—å‰åå·¥åºåˆ†å¸ƒå¯¹æ¯”
    print("ğŸ“‹ æ¸…æ´—å‰å·¥åºåˆ†å¸ƒ (Top 15):")
    original_stats = df['Step_Name'].value_counts().head(15)
    for i, (op_name, count) in enumerate(original_stats.items(), 1):
        percentage = count / len(df) * 100
        print(f"   {i:2d}. {op_name}: {count:5d}æ¡ ({percentage:4.1f}%)")
    
    print()
    print("ğŸ“‹ æ¸…æ´—åå·¥åºåˆ†å¸ƒ (Top 15):")
    cleaned_stats = df['Cleaned_Operation'].value_counts().head(15)
    for i, (op_name, count) in enumerate(cleaned_stats.items(), 1):
        percentage = count / len(df) * 100
        print(f"   {i:2d}. {op_name}: {count:5d}æ¡ ({percentage:4.1f}%)")
    
    print()
    
    # éªŒè¯åˆå¹¶ç»„
    print("ğŸ” åˆå¹¶ç»„éªŒè¯:")
    merge_groups = {
        "çº¿åˆ‡å‰²": ["CZM çº¿åˆ‡å‰²", "CZM çº¿åˆ‡å‰²ï¼ˆå¯å¤–åï¼‰", "CZM çº¿åˆ‡å‰²-æ…¢ä¸ï¼ˆå¯å¤–åï¼‰"],
        "æ•°æ§é“£": ["CZM æ•°æ§é“£", "CZM æ•°æ§é“£ï¼ˆå¯å¤–åï¼‰"],
        "çºµåˆ‡è½¦": ["CZM çºµåˆ‡è½¦", "CZM çºµåˆ‡è½¦ï¼ˆå¯å¤–åï¼‰"],
        "æ•°æ§è½¦": ["CZM æ•°æ§è½¦", "CZM æ•°æ§è½¦ï¼ˆå¯å¤–åï¼‰"],
        "è½¦å‰Š": ["CZM è½¦å‰Š", "CZM è½¦å‰Šï¼ˆå¯å¤–åï¼‰"],
        "é”¯": ["CZM é”¯", "CZM é”¯ï¼ˆå¯å¤–åï¼‰"]
    }
    
    all_merge_correct = True
    for target_op, source_ops in merge_groups.items():
        print(f"\n   ğŸ“¦ {target_op} åˆå¹¶ç»„:")
        total_count = 0
        source_details = []
        
        for source_op in source_ops:
            count = df[df['Step_Name'] == source_op].shape[0]
            if count > 0:
                source_details.append(f"      {source_op}: {count}æ¡")
                total_count += count
        
        for detail in source_details:
            print(detail)
        
        cleaned_count = df[df['Cleaned_Operation'] == target_op].shape[0]
        print(f"      â†’ {target_op}: {cleaned_count}æ¡ (æ€»è®¡: {total_count}æ¡)")
        
        if total_count != cleaned_count:
            print(f"      âŒ æ•°é‡ä¸åŒ¹é…ï¼åŸå§‹æ€»è®¡: {total_count}, æ¸…æ´—å: {cleaned_count}")
            all_merge_correct = False
        else:
            print(f"      âœ… åˆå¹¶æ­£ç¡®")
    
    print()
    
    # éªŒè¯ç‹¬ç«‹å·¥åº
    print("ğŸ” ç‹¬ç«‹å·¥åºéªŒè¯:")
    independent_ops = [
        ("é’åŒ–", "CZM é’åŒ–"),
        ("ç‚¹é’åŒ–", "CZM ç‚¹é’åŒ–"),
        ("çœŸç©ºçƒ­å¤„ç†", "CZM çœŸç©ºçƒ­å¤„ç†"),
        ("çœŸç©ºçƒ­å¤„ç†", "CZM çœŸç©ºçƒ­å¤„ç†ï¼ˆå¯å¤–åï¼‰"),
        ("éçœŸç©ºçƒ­å¤„ç†", "CZM éçœŸç©ºçƒ­å¤„ç†"),
        ("å–·ç ‚", "CZM å–·ç ‚"),
        ("å¾®å–·ç ‚", "CZM å¾®å–·ç ‚"),
        ("ç ”ç£¨", "CZM ç ”ç£¨"),
        ("æ— å¿ƒç£¨", "CZM æ— å¿ƒç£¨"),
        ("æ— å¿ƒç£¨", "CZM æ— å¿ƒç£¨ï¼ˆå¯å¤–åï¼‰")
    ]
    
    all_independent_correct = True
    for target_op, source_op in independent_ops:
        source_count = df[df['Step_Name'] == source_op].shape[0]
        if source_count > 0:
            cleaned_count = df[df['Cleaned_Operation'] == target_op].shape[0]
            print(f"   {source_op} -> {target_op}: {source_count}æ¡")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å·¥åºä¹Ÿæ˜ å°„åˆ°äº†è¿™ä¸ªç›®æ ‡å·¥åº
            target_sources = df[df['Cleaned_Operation'] == target_op]['Step_Name'].unique()
            expected_sources = [op for _, op in independent_ops if _ == target_op]
            unexpected_sources = [op for op in target_sources if op not in expected_sources and not op.startswith("CZM ")]
            
            if unexpected_sources:
                print(f"      âš ï¸  å‘ç°æ„å¤–æ˜ å°„: {unexpected_sources}")
                all_independent_correct = False
            else:
                print(f"      âœ… æ˜ å°„æ­£ç¡®")
    
    print()
    
    # ç”Ÿæˆæ¸…æ´—æ˜ å°„è¡¨
    print("ğŸ“ æ¸…æ´—æ˜ å°„è¡¨:")
    mapping_df = df[['Step_Name', 'Cleaned_Operation']].drop_duplicates().sort_values('Step_Name')
    
    # åªæ˜¾ç¤ºæœ‰å˜åŒ–çš„æ˜ å°„
    changed_mapping = mapping_df[mapping_df['Step_Name'] != mapping_df['Cleaned_Operation']]
    
    print(f"   æ€»æ˜ å°„æ•°: {len(mapping_df)}")
    print(f"   æœ‰å˜åŒ–çš„æ˜ å°„: {len(changed_mapping)}")
    print()
    
    # ä¿å­˜æ¸…æ´—ç»“æœ
    output_path = r"c:\Users\huangk14\OneDrive - Medtronic PLC\Huangkai Files\B1_Project\250418_MDDAP_project\10-SAæŒ‡æ ‡\13-SAæ•°æ®æ¸…æ´—\operation_cleaning_result.csv"
    
    # ä¿å­˜å®Œæ•´çš„æ¸…æ´—ç»“æœæ ·æœ¬ï¼ˆå‰1000æ¡ï¼‰
    sample_df = df.head(1000)[['Step_Name', 'Cleaned_Operation']]
    sample_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ æ¸…æ´—ç»“æœæ ·æœ¬å·²ä¿å­˜: {output_path}")
    
    # ä¿å­˜æ˜ å°„è¡¨
    mapping_output_path = r"c:\Users\huangk14\OneDrive - Medtronic PLC\Huangkai Files\B1_Project\250418_MDDAP_project\10-SAæŒ‡æ ‡\13-SAæ•°æ®æ¸…æ´—\operation_mapping.csv"
    mapping_df.to_csv(mapping_output_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ æ¸…æ´—æ˜ å°„è¡¨å·²ä¿å­˜: {mapping_output_path}")
    
    print()
    print("=" * 80)
    
    # æœ€ç»ˆç»“æœ
    if all_merge_correct and all_independent_correct:
        print("ğŸ‰ éªŒè¯å®Œæˆï¼æ‰€æœ‰æ¸…æ´—è§„åˆ™éƒ½æ­£ç¡®å®æ–½")
        print("âœ… MESå·¥åºæ¸…æ´—åŠŸèƒ½å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥æŠ•å…¥ä½¿ç”¨")
    else:
        print("âš ï¸  éªŒè¯å‘ç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ¸…æ´—é€»è¾‘")
    
    print()
    print("ğŸ“Š æ¸…æ´—æ•ˆæœæ€»ç»“:")
    print(f"   â€¢ å·¥åºæ•°é‡ä» {original_count} ä¸ªå‡å°‘åˆ° {cleaned_count} ä¸ª")
    print(f"   â€¢ æˆåŠŸåˆå¹¶ 6 ä¸ªå·¥åºç»„")
    print(f"   â€¢ ä¿æŒ 29 ä¸ªç‹¬ç«‹å·¥åº")
    print(f"   â€¢ å»é™¤æ‰€æœ‰ CZM å‰ç¼€å’Œå¤–åæ ‡è¯†")
    print(f"   â€¢ æ•°æ®å®Œæ•´æ€§: {len(df):,} æ¡è®°å½•æ— æŸå¤±")

if __name__ == "__main__":
    generate_cleaning_report()
