# ETL Process Roadmap & Architecture

æ­¤æ–‡æ¡£è¯¦ç»†å±•ç¤ºäº†ä»**åŸå§‹æ•°æ®æ¸…æ´—**åˆ°**æœ€ç»ˆè¾“å‡º Parquet** çš„æ ¸å¿ƒæ•°æ®æµè½¬è¿‡ç¨‹ã€‚

## ğŸ—ºï¸ æ€»ä½“å…¨æ™¯å›¾ (High Level)

```mermaid
graph TD
    subgraph "1. Ingestion (é‡‡é›†)"
        RawFiles[ğŸ“‚ Raw Excel/CSV<br/>(Planner, MES, SFC, SAP)]
    end

    subgraph "2. Processing (å¤„ç†)"
        HashCheck{âš¡ Incremental Check<br/>(Hash/MTime)}
        Cleaning[ğŸ§¹ Python ETL Scripts<br/>(Clean & Normalize)]
        SQL[(ğŸ›¢ï¸ SQL Server<br/>Data Warehouse)]
        Snapshots[ğŸ“¸ Materialized Views<br/>(Optimization)]
    end

    subgraph "3. Export (è¾“å‡º)"
        Exporter[ğŸ“¤ Exporter Script<br/>(export_core_to_a1.py)]
        Parquet[ğŸ“¦ Partitioned Parquet<br/>(Target for Power BI)]
    end

    RawFiles --> HashCheck
    HashCheck -- New/Changed --> Cleaning
    HashCheck -- No Change --> End((Skip))
    Cleaning --> SQL
    SQL --> Snapshots
    Snapshots --> Exporter
    SQL --> Exporter
    Exporter --> Parquet
```

---

## ğŸ” è¯¦ç»†æ•°æ®æµè½¬ (Detailed Data Flow)

### é˜¶æ®µ 1: åŸå§‹æ•°æ®å¤„ç† (Raw to SQL)

æ¯ä¸ªæ•°æ®æºéƒ½æœ‰ç‹¬ç«‹çš„ ETL è„šæœ¬è´Ÿè´£æ¸…æ´—å’Œå…¥åº“ã€‚

```mermaid
flowchart LR
    %% Data Sources
    MES_File[ğŸ“„ MES Batch Report]
    SFC_File[ğŸ“„ SFC Batch/Insp]
    SAP_File[ğŸ“„ SAP Routing/Labor]
    
    %% Incremental Logic
    subgraph "Incremental Logic"
        CheckState[1. Check State File]
        CalcHash[2. Calculate File Hash]
        Compare{3. Compare?}
    end
    
    %% Cleaning Logic
    subgraph "Cleaning & Loading"
        CleanHeaders[4. Standardize Headers]
        TypeCast[5. Type Casting]
        LoadDB[6. UPSERT into SQL Server]
    end
    
    MES_File --> CheckState --> CalcHash --> Compare
    SFC_File --> CheckState --> CalcHash --> Compare
    SAP_File --> CheckState --> CalcHash --> Compare
    
    Compare -- Changed --> CleanHeaders --> TypeCast --> LoadDB
    Compare -- Same --> Skip((Skip))
    
    LoadDB --> SQL_Raw[(SQL Raw Tables)]
```

### é˜¶æ®µ 2: ç»´åº¦ä¸æŒ‡æ ‡è®¡ç®— (Enrichment)

æ•°æ®å…¥åº“åï¼Œè¿›è¡Œå…³è”è®¡ç®—å’Œå¿«ç…§ç”Ÿæˆã€‚

```mermaid
flowchart TD
    SQL_Raw[(SQL Raw Tables)]
    
    subgraph "2.1 Dimensions"
        Calendar[Calendar Dim]
        OpsMap[Operation Mapping]
    end
    
    subgraph "2.2 WIP & Metrics"
        WIP_Calc[WIP Calculation<br/>(MES & SFC)]
        Views[SQL Views<br/>(v_mes_metrics)]
    end
    
    subgraph "2.3 Materialization"
        RefreshScript[ğŸ”„ _refresh_mes_metrics.py]
        SnapshotA[Table: snapshot_a]
        SnapshotB[Table: snapshot_b]
        Synonym[Synonym: current_snapshot]
    end
    
    SQL_Raw --> Calendar & OpsMap
    SQL_Raw --> WIP_Calc
    SQL_Raw --> Views
    
    Views --> RefreshScript
    RefreshScript -- Clean & Fill --> SnapshotA
    RefreshScript -- Switch/Swap --> SnapshotB
    SnapshotA & SnapshotB -.-> Synonym
```

### é˜¶æ®µ 3: æœ€ç»ˆå¯¼å‡º (Export to Parquet)

ä¸ºäº†ç»™ Power BI æä¾›é«˜æ€§èƒ½è¯»å–ï¼Œæˆ‘ä»¬å°† SQL æ•°æ®å¯¼å‡ºä¸º **Partitioned Parquet** æ–‡ä»¶ã€‚

```mermaid
graph TD
    Synonym[(SQL Data / Snapshots)]
    
    subgraph "Export Process (export_core_to_a1.py)"
        Reader[1. Read via ODBC]
        Transformer[2. Transform (Pandas)]
        Partitioner[3. Partition Logic<br/>(Year/Month)]
        Writer[4. Write Parquet]
    end
    
    Folder[ğŸ“‚ Output Folder<br/>(A1_ETL_Output)]
    PBI[ğŸ“Š Power BI]
    
    Synonym --> Reader
    Reader --> Transformer
    Transformer --> Partitioner
    Partitioner --> Writer
    Writer --> Folder
    Folder --> PBI
```

## ğŸ—ï¸ å…³é”®åŠ¨ä½œè¯´æ˜ (Key Actions)

| æ­¥éª¤ | åŠ¨ä½œ (Action) | è´Ÿè´£è„šæœ¬ | è¯´æ˜ |
| :--- | :--- | :--- | :--- |
| **0. é‡‡é›†** | **Data Collection** | `run_data_collection.py` | æ™ºèƒ½çˆ¬è™«ä» Planner/CMES è·å–æœ€æ–° Excelã€‚ |
| **1. å¢é‡æ£€æŸ¥** | **Hashing** | `etl_utils.py` | è·å–æ–‡ä»¶çš„ `mtime` å’Œ `size`ï¼Œä¸ `state.json` å¯¹æ¯”ï¼Œå†³å®šæ˜¯å¦è·³è¿‡ã€‚ |
| **2. æ¸…æ´—** | **Normalization** | `etl_*.py` | ç»Ÿä¸€åˆ—åï¼ˆå¦‚ `BatchID` vs `Batch_No`ï¼‰ï¼Œä¿®å¤æ—¥æœŸæ ¼å¼ï¼Œå¤„ç†ç©ºå€¼ã€‚ |
| **3. å…¥åº“** | **Upsert** | `db_utils.py` | ä½¿ç”¨ SQL `MERGE` æˆ– `DELETE+INSERT` ç¡®ä¿æ•°æ®åº“ä¸­æœ€æ–°çš„æ•°æ®ã€‚ |
| **4. è®¡ç®—** | **Materialize** | `_refresh_*.py` | å¯¹äºå¤æ‚çš„èšåˆæŸ¥è¯¢ï¼Œé¢„å…ˆè®¡ç®—å¹¶å­˜å…¥ç‰©ç†è¡¨ï¼Œé¿å… PBI æŸ¥è¯¢è¶…æ—¶ã€‚ |
| **5. å¯¼å‡º** | **Parquet Export** | `export_core_to_a1.py` | å°† SQL æ•°æ®æŒ‰å¹´æœˆåˆ†ç‰‡å¯¼å‡ºä¸º Parquetï¼Œæ¯ä¸ªæ–‡ä»¶æå°ä¸”å¸¦å‹ç¼©ã€‚ |

---
*æœ¬æ–‡æ¡£ç”± MDDAP å¯¹è¯åŠ©æ‰‹è‡ªåŠ¨ç”Ÿæˆã€‚*
