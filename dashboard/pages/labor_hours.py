"""
å·¥æ—¶åˆ†æçœ‹æ¿
Labor Hours Dashboard

åŸºäºè¡Œä¸šæœ€ä½³å®è·µè®¾è®¡çš„å·¥æ—¶åˆ†æçœ‹æ¿ï¼ŒåŒ…å«ï¼š
- KPI å¡ç‰‡ï¼šæ€»å·¥æ—¶ã€å½“æœˆå·¥æ—¶ã€YTDå·¥æ—¶ã€ç¯æ¯”/åŒæ¯”
- è¶‹åŠ¿å›¾ï¼šæ¯æ—¥/æ¯å‘¨/æ¯æœˆå·¥æ—¶è¶‹åŠ¿
- åˆ†å¸ƒå›¾ï¼šæŒ‰å·¥ä½œä¸­å¿ƒã€å·¥åºã€ç‰©æ–™åˆ†å¸ƒ
- æ˜ç»†è¡¨ï¼šå¯ç­›é€‰çš„å·¥æ—¶æ˜ç»†æ•°æ®
"""

import streamlit as st
import pyodbc
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import os

# SQL Server è¿æ¥é…ç½®ï¼ˆå¯ç”¨ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
SQL_SERVER = os.getenv('MDDAP_SQL_SERVER', r'localhost\SQLEXPRESS')
SQL_DATABASE = os.getenv('MDDAP_SQL_DATABASE', 'mddap_v2')
SQL_DRIVER = os.getenv('MDDAP_SQL_DRIVER', 'ODBC Driver 17 for SQL Server')

def get_db_connection():
    """åˆ›å»ºæ•°æ®åº“è¿æ¥"""
    try:
        conn_str = (
            f"DRIVER={{{SQL_DRIVER}}};"
            f"SERVER={SQL_SERVER};"
            f"DATABASE={SQL_DATABASE};"
            "Trusted_Connection=yes;"
            "Encrypt=no;"
        )
        return pyodbc.connect(conn_str, autocommit=False)
    except Exception as e:
        st.error(f"è¿æ¥æ•°æ®åº“å¤±è´¥: {str(e)}")
        return None

@st.cache_data(ttl=300)
def load_labor_hours_data():
    """åŠ è½½å·¥æ—¶æ•°æ®"""
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    query = """
    SELECT 
        PostingDate as posting_date,
        Plant as plant,
        WorkCenter as work_center,
        WorkCenterDesc as work_center_desc,
        CostCenter as cost_center,
        Material as material,
        MaterialDesc as material_desc,
        MaterialType as material_type,
        OrderNumber as order_no,
        OrderType as order_type,
        Operation as operation,
        OperationDesc as operation_desc,
        ProductionScheduler as scheduler,
        ProductionSchedulerDesc as scheduler_desc,
        EarnedLaborTime as labor_hours,
        MachineTime as machine_hours,
        ActualQuantity as actual_qty,
        ActualScrapQty as scrap_qty,
        TargetQuantity as target_qty
    FROM dbo.raw_sap_labor_hours
    WHERE PostingDate IS NOT NULL
    """
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    if not df.empty:
        df['posting_date'] = pd.to_datetime(df['posting_date'])
        df['year'] = df['posting_date'].dt.year
        df['month'] = df['posting_date'].dt.month
        df['week'] = df['posting_date'].dt.isocalendar().week
        df['weekday'] = df['posting_date'].dt.dayofweek
        df['year_month'] = df['posting_date'].dt.to_period('M').astype(str)
    
    return df

@st.cache_data(ttl=300)
def load_calendar_data():
    """åŠ è½½æ—¥å†æ•°æ®"""
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    query = """
    SELECT 
        date,
        fiscal_year,
        fiscal_month,
        fiscal_week,
        fiscal_quarter,
        is_workday,
        holiday_name
    FROM dbo.dim_calendar
    """
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    if not df.empty:
        df['date'] = pd.to_datetime(df['date'])
    
    return df

@st.cache_data(ttl=300)
def load_planned_hours_data():
    """åŠ è½½è®¡åˆ’å·¥æ—¶æ•°æ®"""
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    query = """
    SELECT 
        plan_date,
        cz_planned_hours,
        kh_planned_hours
    FROM dbo.planned_labor_hours
    WHERE plan_date IS NOT NULL
    """
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    if not df.empty:
        df['plan_date'] = pd.to_datetime(df['plan_date'])
    
    return df

def calculate_kpis(df, df_calendar, df_planned, selected_date_range):
    """è®¡ç®— KPI æŒ‡æ ‡"""
    if df.empty:
        return {}
    
    # ç­›é€‰æ—¥æœŸèŒƒå›´
    start_date, end_date = selected_date_range
    mask = (df['posting_date'] >= pd.Timestamp(start_date)) & (df['posting_date'] <= pd.Timestamp(end_date))
    df_filtered = df[mask]
    
    # å½“å‰é€‰æ‹©èŒƒå›´çš„å·¥æ—¶
    total_labor = df_filtered['labor_hours'].sum()
    total_machine = df_filtered['machine_hours'].sum()
    total_qty = df_filtered['actual_qty'].sum()
    total_scrap = df_filtered['scrap_qty'].sum()
    
    # è®¡åˆ’å·¥æ—¶
    if not df_planned.empty:
        plan_mask = (df_planned['plan_date'] >= pd.Timestamp(start_date)) & (df_planned['plan_date'] <= pd.Timestamp(end_date))
        df_plan_filtered = df_planned[plan_mask]
        planned_cz = df_plan_filtered['cz_planned_hours'].sum()
        planned_kh = df_plan_filtered['kh_planned_hours'].sum()
        total_planned = planned_cz + planned_kh
    else:
        planned_cz = planned_kh = total_planned = 0
    
    # è¾¾æˆç‡
    achievement_rate = (total_labor / total_planned * 100) if total_planned > 0 else 0
    variance = total_labor - total_planned
    
    # å½“æœˆå·¥æ—¶ (åŸºäºç»“æŸæ—¥æœŸçš„æœˆä»½)
    current_month = end_date.month
    current_year = end_date.year
    month_mask = (df['posting_date'].dt.month == current_month) & (df['posting_date'].dt.year == current_year)
    month_labor = df[month_mask]['labor_hours'].sum()
    
    # YTD å·¥æ—¶
    ytd_mask = (df['posting_date'].dt.year == current_year) & (df['posting_date'] <= pd.Timestamp(end_date))
    ytd_labor = df[ytd_mask]['labor_hours'].sum()
    
    # ä¸Šæœˆå·¥æ—¶ (ç¯æ¯”)
    last_month = current_month - 1 if current_month > 1 else 12
    last_month_year = current_year if current_month > 1 else current_year - 1
    last_month_mask = (df['posting_date'].dt.month == last_month) & (df['posting_date'].dt.year == last_month_year)
    last_month_labor = df[last_month_mask]['labor_hours'].sum()
    
    # å»å¹´åŒæœˆ (åŒæ¯”)
    last_year_mask = (df['posting_date'].dt.month == current_month) & (df['posting_date'].dt.year == current_year - 1)
    last_year_labor = df[last_year_mask]['labor_hours'].sum()
    
    # è®¡ç®—å¢é•¿ç‡
    mom_growth = ((month_labor - last_month_labor) / last_month_labor * 100) if last_month_labor > 0 else 0
    yoy_growth = ((month_labor - last_year_labor) / last_year_labor * 100) if last_year_labor > 0 else 0
    
    # æŠ¥åºŸç‡
    scrap_rate = (total_scrap / (total_qty + total_scrap) * 100) if (total_qty + total_scrap) > 0 else 0
    
    # å·¥ä½œæ—¥æ•° (ä»æ—¥å†è¡¨)
    if not df_calendar.empty:
        cal_mask = (df_calendar['date'] >= pd.Timestamp(start_date)) & (df_calendar['date'] <= pd.Timestamp(end_date))
        workdays = df_calendar[cal_mask & (df_calendar['is_workday'] == 1)].shape[0]
    else:
        workdays = (end_date - start_date).days + 1
    
    avg_daily_hours = total_labor / workdays if workdays > 0 else 0
    
    return {
        'total_labor': total_labor,
        'total_machine': total_machine,
        'total_qty': total_qty,
        'total_scrap': total_scrap,
        'total_planned': total_planned,
        'planned_cz': planned_cz,
        'planned_kh': planned_kh,
        'achievement_rate': achievement_rate,
        'variance': variance,
        'month_labor': month_labor,
        'ytd_labor': ytd_labor,
        'mom_growth': mom_growth,
        'yoy_growth': yoy_growth,
        'scrap_rate': scrap_rate,
        'workdays': workdays,
        'avg_daily_hours': avg_daily_hours
    }

def render_kpi_cards(kpis):
    """æ¸²æŸ“ KPI å¡ç‰‡"""
    # ç¬¬ä¸€è¡Œ KPI - å®é™…ä¸è®¡åˆ’å¯¹æ¯”
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ğŸ“Š å®é™…å·¥æ—¶",
            value=f"{kpis.get('total_labor', 0):,.1f} å°æ—¶",
            delta=f"è®¡åˆ’: {kpis.get('total_planned', 0):,.1f} å°æ—¶"
        )
    
    with col2:
        st.metric(
            label="ğŸ¯ è¾¾æˆç‡",
            value=f"{kpis.get('achievement_rate', 0):.1f}%",
            delta=f"{kpis.get('variance', 0):+.1f} å°æ—¶"
        )
    
    with col3:
        st.metric(
            label="ğŸ“… å½“æœˆå·¥æ—¶",
            value=f"{kpis.get('month_labor', 0):,.1f} å°æ—¶",
            delta=f"{kpis.get('mom_growth', 0):+.1f}% ç¯æ¯”"
        )
    
    with col4:
        st.metric(
            label="ğŸ“ˆ YTD å·¥æ—¶",
            value=f"{kpis.get('ytd_labor', 0):,.1f} å°æ—¶",
            delta=f"{kpis.get('yoy_growth', 0):+.1f}% åŒæ¯”"
        )
    
    # ç¬¬äºŒè¡Œ KPI - å·¥å‚åˆ†è§£
    col5, col6, col7, col8 = st.columns(4)
    
    with col5:
        st.metric(
            label="ğŸ­ å¸¸å·è®¡åˆ’",
            value=f"{kpis.get('planned_cz', 0):,.1f} å°æ—¶",
            delta=None
        )
    
    with col6:
        st.metric(
            label="ğŸ­ åº·è¾‰è®¡åˆ’",
            value=f"{kpis.get('planned_kh', 0):,.1f} å°æ—¶",
            delta=None
        )
    
    with col7:
        st.metric(
            label="âš™ï¸ æœºå™¨å·¥æ—¶",
            value=f"{kpis.get('total_machine', 0):,.1f} å°æ—¶",
            delta=None
        )
    
    with col8:
        st.metric(
            label="â±ï¸ æ—¥å‡å·¥æ—¶",
            value=f"{kpis.get('avg_daily_hours', 0):,.1f} å°æ—¶/å¤©",
            delta=None
        )
    
    # ç¬¬ä¸‰è¡Œ KPI - å…¶ä»–æŒ‡æ ‡
    col9, col10, col11, col12 = st.columns(4)
    
    with col9:
        st.metric(
            label="ğŸ“¦ å®é™…äº§é‡",
            value=f"{kpis.get('total_qty', 0):,.0f}",
            delta=None
        )
    
    with col10:
        st.metric(
            label="ğŸ—‘ï¸ æŠ¥åºŸæ•°é‡",
            value=f"{kpis.get('total_scrap', 0):,.0f}",
            delta=f"{kpis.get('scrap_rate', 0):.2f}% æŠ¥åºŸç‡"
        )
    
    with col11:
        st.metric(
            label="ğŸ“† å·¥ä½œæ—¥æ•°",
            value=f"{kpis.get('workdays', 0)} å¤©",
            delta=None
        )
    
    with col12:
        st.metric(
            label="ğŸ“Š æ•ˆç‡æŒ‡æ•°",
            value=f"{kpis.get('achievement_rate', 0) / 100:.2f}",
            delta=None
        )

def render_trend_chart(df, df_planned, date_range, granularity='daily'):
    """æ¸²æŸ“è¶‹åŠ¿å›¾"""
    start_date, end_date = date_range
    mask = (df['posting_date'] >= pd.Timestamp(start_date)) & (df['posting_date'] <= pd.Timestamp(end_date))
    df_filtered = df[mask].copy()
    
    if df_filtered.empty:
        st.warning("é€‰å®šæ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ•°æ®")
        return
    
    # å¤„ç†å®é™…å·¥æ—¶æ•°æ®
    if granularity == 'daily':
        trend_df = df_filtered.groupby('posting_date').agg({
            'labor_hours': 'sum',
            'machine_hours': 'sum',
            'actual_qty': 'sum'
        }).reset_index()
        x_col = 'posting_date'
        x_title = 'æ—¥æœŸ'
    elif granularity == 'weekly':
        df_filtered['year_week'] = df_filtered['posting_date'].dt.strftime('%Y-W%W')
        trend_df = df_filtered.groupby('year_week').agg({
            'labor_hours': 'sum',
            'machine_hours': 'sum',
            'actual_qty': 'sum'
        }).reset_index()
        x_col = 'year_week'
        x_title = 'å‘¨'
    else:  # monthly
        trend_df = df_filtered.groupby('year_month').agg({
            'labor_hours': 'sum',
            'machine_hours': 'sum',
            'actual_qty': 'sum'
        }).reset_index()
        x_col = 'year_month'
        x_title = 'æœˆä»½'
    
    # å¤„ç†è®¡åˆ’å·¥æ—¶æ•°æ®
    if not df_planned.empty:
        plan_mask = (df_planned['plan_date'] >= pd.Timestamp(start_date)) & (df_planned['plan_date'] <= pd.Timestamp(end_date))
        df_plan_filtered = df_planned[plan_mask].copy()
        
        if granularity == 'daily':
            df_plan_filtered = df_plan_filtered.set_index('plan_date')
            df_plan_filtered['total_planned'] = df_plan_filtered['cz_planned_hours'] + df_plan_filtered['kh_planned_hours']
            plan_df = df_plan_filtered[['total_planned']].reset_index()
            plan_df.columns = [x_col, 'planned_hours']
        elif granularity == 'weekly':
            df_plan_filtered['year_week'] = df_plan_filtered['plan_date'].dt.strftime('%Y-W%W')
            df_plan_filtered['total_planned'] = df_plan_filtered['cz_planned_hours'] + df_plan_filtered['kh_planned_hours']
            plan_df = df_plan_filtered.groupby('year_week')['total_planned'].sum().reset_index()
            plan_df.columns = [x_col, 'planned_hours']
        else:  # monthly
            df_plan_filtered['year_month'] = df_plan_filtered['plan_date'].dt.to_period('M').astype(str)
            df_plan_filtered['total_planned'] = df_plan_filtered['cz_planned_hours'] + df_plan_filtered['kh_planned_hours']
            plan_df = df_plan_filtered.groupby('year_month')['total_planned'].sum().reset_index()
            plan_df.columns = [x_col, 'planned_hours']
    else:
        plan_df = pd.DataFrame(columns=[x_col, 'planned_hours'])
    
    # åˆå¹¶å®é™…å’Œè®¡åˆ’æ•°æ®
    merged_df = pd.merge(trend_df, plan_df, on=x_col, how='left')
    
    fig = go.Figure()
    
    # å®é™…å·¥æ—¶ï¼ˆæŸ±çŠ¶å›¾ï¼‰
    fig.add_trace(go.Bar(
        x=merged_df[x_col],
        y=merged_df['labor_hours'],
        name='å®é™…äººå·¥å·¥æ—¶',
        marker_color='#1f77b4'
    ))
    
    # è®¡åˆ’å·¥æ—¶ï¼ˆæŠ˜çº¿å›¾ï¼‰
    fig.add_trace(go.Scatter(
        x=merged_df[x_col],
        y=merged_df['planned_hours'],
        name='è®¡åˆ’å·¥æ—¶',
        mode='lines+markers',
        yaxis='y2',
        line=dict(color='#2ca02c', width=2)
    ))
    
    # æœºå™¨å·¥æ—¶ï¼ˆæŠ˜çº¿å›¾ï¼‰
    fig.add_trace(go.Scatter(
        x=merged_df[x_col],
        y=merged_df['machine_hours'],
        name='æœºå™¨å·¥æ—¶',
        mode='lines+markers',
        yaxis='y3',
        line=dict(color='#ff7f0e', width=2)
    ))
    
    fig.update_layout(
        title=f'å·¥æ—¶è¶‹åŠ¿å¯¹æ¯” ({granularity})',
        xaxis_title=x_title,
        yaxis=dict(title='å®é™…äººå·¥å·¥æ—¶ (å°æ—¶)'),
        yaxis2=dict(title='è®¡åˆ’å·¥æ—¶ (å°æ—¶)', overlaying='y', side='right'),
        yaxis3=dict(title='æœºå™¨å·¥æ—¶ (å°æ—¶)', overlaying='y', side='right', position=0.85),
        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),
        height=400,
        hovermode='x unified'
    )
    
    st.plotly_chart(fig, use_container_width=True)

def render_distribution_charts(df, date_range):
    """æ¸²æŸ“åˆ†å¸ƒå›¾"""
    start_date, end_date = date_range
    mask = (df['posting_date'] >= pd.Timestamp(start_date)) & (df['posting_date'] <= pd.Timestamp(end_date))
    df_filtered = df[mask]
    
    if df_filtered.empty:
        st.warning("é€‰å®šæ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ•°æ®")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        # æŒ‰å·¥ä½œä¸­å¿ƒåˆ†å¸ƒ
        wc_df = df_filtered.groupby('work_center_desc')['labor_hours'].sum().reset_index()
        wc_df = wc_df.sort_values('labor_hours', ascending=False).head(10)
        
        fig1 = px.bar(
            wc_df,
            x='labor_hours',
            y='work_center_desc',
            orientation='h',
            title='Top 10 å·¥ä½œä¸­å¿ƒå·¥æ—¶åˆ†å¸ƒ',
            labels={'labor_hours': 'å·¥æ—¶ (å°æ—¶)', 'work_center_desc': 'å·¥ä½œä¸­å¿ƒ'}
        )
        fig1.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})
        st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        # æŒ‰å·¥åºåˆ†å¸ƒ
        op_df = df_filtered.groupby('operation_desc')['labor_hours'].sum().reset_index()
        op_df = op_df.sort_values('labor_hours', ascending=False).head(10)
        
        fig2 = px.bar(
            op_df,
            x='labor_hours',
            y='operation_desc',
            orientation='h',
            title='Top 10 å·¥åºå·¥æ—¶åˆ†å¸ƒ',
            labels={'labor_hours': 'å·¥æ—¶ (å°æ—¶)', 'operation_desc': 'å·¥åº'}
        )
        fig2.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})
        st.plotly_chart(fig2, use_container_width=True)
    
    col3, col4 = st.columns(2)
    
    with col3:
        # æŒ‰ç‰©æ–™ç±»å‹åˆ†å¸ƒ (é¥¼å›¾)
        mt_df = df_filtered.groupby('material_type')['labor_hours'].sum().reset_index()
        mt_df = mt_df[mt_df['labor_hours'] > 0]
        
        fig3 = px.pie(
            mt_df,
            values='labor_hours',
            names='material_type',
            title='ç‰©æ–™ç±»å‹å·¥æ—¶å æ¯”',
            hole=0.4
        )
        fig3.update_layout(height=400)
        st.plotly_chart(fig3, use_container_width=True)
    
    with col4:
        # æŒ‰è®¢å•ç±»å‹åˆ†å¸ƒ
        ot_df = df_filtered.groupby('order_type')['labor_hours'].sum().reset_index()
        ot_df = ot_df[ot_df['labor_hours'] > 0]
        
        fig4 = px.pie(
            ot_df,
            values='labor_hours',
            names='order_type',
            title='è®¢å•ç±»å‹å·¥æ—¶å æ¯”',
            hole=0.4
        )
        fig4.update_layout(height=400)
        st.plotly_chart(fig4, use_container_width=True)

def render_heatmap(df, date_range):
    """æ¸²æŸ“çƒ­åŠ›å›¾ - æŒ‰æ˜ŸæœŸå’Œå·¥ä½œä¸­å¿ƒ"""
    start_date, end_date = date_range
    mask = (df['posting_date'] >= pd.Timestamp(start_date)) & (df['posting_date'] <= pd.Timestamp(end_date))
    df_filtered = df[mask]
    
    if df_filtered.empty:
        return
    
    # æŒ‰æ˜ŸæœŸå‡ å’Œå·¥ä½œä¸­å¿ƒæ±‡æ€»
    weekday_names = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
    df_filtered['weekday_name'] = df_filtered['weekday'].map(lambda x: weekday_names[x])
    
    # è·å– Top 10 å·¥ä½œä¸­å¿ƒ
    top_wc = df_filtered.groupby('work_center_desc')['labor_hours'].sum().nlargest(10).index.tolist()
    df_top = df_filtered[df_filtered['work_center_desc'].isin(top_wc)]
    
    heatmap_df = df_top.pivot_table(
        values='labor_hours',
        index='work_center_desc',
        columns='weekday_name',
        aggfunc='sum',
        fill_value=0
    )
    
    # é‡æ–°æ’åºåˆ—
    heatmap_df = heatmap_df.reindex(columns=weekday_names, fill_value=0)
    
    fig = px.imshow(
        heatmap_df,
        labels=dict(x='æ˜ŸæœŸ', y='å·¥ä½œä¸­å¿ƒ', color='å·¥æ—¶'),
        title='å·¥ä½œä¸­å¿ƒ Ã— æ˜ŸæœŸ å·¥æ—¶çƒ­åŠ›å›¾',
        color_continuous_scale='Blues'
    )
    fig.update_layout(height=400)
    st.plotly_chart(fig, use_container_width=True)

def render_detail_table(df, date_range):
    """æ¸²æŸ“æ˜ç»†è¡¨"""
    start_date, end_date = date_range
    mask = (df['posting_date'] >= pd.Timestamp(start_date)) & (df['posting_date'] <= pd.Timestamp(end_date))
    df_filtered = df[mask].copy()
    
    if df_filtered.empty:
        st.warning("é€‰å®šæ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ•°æ®")
        return
    
    # æ˜¾ç¤ºåˆ—é€‰æ‹©
    display_cols = [
        'posting_date', 'work_center_desc', 'operation_desc', 
        'material_desc', 'order_no', 'labor_hours', 'machine_hours',
        'actual_qty', 'scrap_qty'
    ]
    
    df_display = df_filtered[display_cols].copy()
    df_display.columns = [
        'æ—¥æœŸ', 'å·¥ä½œä¸­å¿ƒ', 'å·¥åº', 'ç‰©æ–™æè¿°', 'è®¢å•å·',
        'äººå·¥å·¥æ—¶', 'æœºå™¨å·¥æ—¶', 'å®é™…æ•°é‡', 'æŠ¥åºŸæ•°é‡'
    ]
    
    # æ ¼å¼åŒ–æ—¥æœŸ
    df_display['æ—¥æœŸ'] = df_display['æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
    
    st.dataframe(
        df_display,
        use_container_width=True,
        height=400,
        hide_index=True
    )
    
    # ä¸‹è½½æŒ‰é’®
    csv = df_display.to_csv(index=False, encoding='utf-8-sig')
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½æ•°æ® (CSV)",
        data=csv,
        file_name=f"labor_hours_{start_date}_{end_date}.csv",
        mime="text/csv"
    )

def main():
    st.title("â±ï¸ å·¥æ—¶åˆ†æçœ‹æ¿")
    st.markdown("---")
    
    # åŠ è½½æ•°æ®
    with st.spinner("åŠ è½½æ•°æ®ä¸­..."):
        df = load_labor_hours_data()
        df_calendar = load_calendar_data()
        df_planned = load_planned_hours_data()
    
    if df.empty:
        st.error("æ²¡æœ‰å·¥æ—¶æ•°æ®ï¼Œè¯·å…ˆå¯¼å…¥æ•°æ®")
        return
    
    # ä¾§è¾¹æ ç­›é€‰å™¨
    st.sidebar.header("ğŸ“… ç­›é€‰æ¡ä»¶")
    
    # æ—¥æœŸèŒƒå›´
    min_date = df['posting_date'].min().date()
    max_date = df['posting_date'].max().date()
    
    # å¿«æ·æ—¥æœŸé€‰æ‹©
    date_preset = st.sidebar.selectbox(
        "å¿«æ·é€‰æ‹©",
        ["è‡ªå®šä¹‰", "æœ¬æœˆ", "ä¸Šæœˆ", "æœ¬å­£åº¦", "æœ¬å¹´", "æœ€è¿‘30å¤©", "æœ€è¿‘90å¤©"]
    )
    
    today = datetime.now().date()
    
    if date_preset == "æœ¬æœˆ":
        start_date = today.replace(day=1)
        end_date = today
    elif date_preset == "ä¸Šæœˆ":
        first_of_month = today.replace(day=1)
        end_date = first_of_month - timedelta(days=1)
        start_date = end_date.replace(day=1)
    elif date_preset == "æœ¬å­£åº¦":
        quarter = (today.month - 1) // 3
        start_date = today.replace(month=quarter * 3 + 1, day=1)
        end_date = today
    elif date_preset == "æœ¬å¹´":
        start_date = today.replace(month=1, day=1)
        end_date = today
    elif date_preset == "æœ€è¿‘30å¤©":
        start_date = today - timedelta(days=30)
        end_date = today
    elif date_preset == "æœ€è¿‘90å¤©":
        start_date = today - timedelta(days=90)
        end_date = today
    else:
        start_date = st.sidebar.date_input("å¼€å§‹æ—¥æœŸ", value=max_date - timedelta(days=30), min_value=min_date, max_value=max_date)
        end_date = st.sidebar.date_input("ç»“æŸæ—¥æœŸ", value=max_date, min_value=min_date, max_value=max_date)
    
    date_range = (start_date, end_date)
    
    st.sidebar.markdown(f"**é€‰å®šèŒƒå›´**: {start_date} ~ {end_date}")
    
    # å·¥ä½œä¸­å¿ƒç­›é€‰
    work_centers = ['å…¨éƒ¨'] + sorted(df['work_center_desc'].dropna().unique().tolist())
    selected_wc = st.sidebar.multiselect("å·¥ä½œä¸­å¿ƒ", work_centers, default=['å…¨éƒ¨'])
    
    if 'å…¨éƒ¨' not in selected_wc and selected_wc:
        df = df[df['work_center_desc'].isin(selected_wc)]
    
    # è®¡ç®— KPI
    kpis = calculate_kpis(df, df_calendar, df_planned, date_range)
    
    # æ¸²æŸ“ KPI å¡ç‰‡
    st.subheader("ğŸ“Š å…³é”®æŒ‡æ ‡")
    render_kpi_cards(kpis)
    
    st.markdown("---")
    
    # è¶‹åŠ¿å›¾
    st.subheader("ğŸ“ˆ å·¥æ—¶è¶‹åŠ¿")
    granularity = st.radio("æ—¶é—´ç²’åº¦", ["daily", "weekly", "monthly"], horizontal=True, format_func=lambda x: {"daily": "æŒ‰æ—¥", "weekly": "æŒ‰å‘¨", "monthly": "æŒ‰æœˆ"}[x])
    render_trend_chart(df, df_planned, date_range, granularity)
    
    st.markdown("---")
    
    # åˆ†å¸ƒå›¾
    st.subheader("ğŸ“Š å·¥æ—¶åˆ†å¸ƒ")
    render_distribution_charts(df, date_range)
    
    st.markdown("---")
    
    # çƒ­åŠ›å›¾
    st.subheader("ğŸ—“ï¸ å·¥æ—¶çƒ­åŠ›å›¾")
    render_heatmap(df, date_range)
    
    st.markdown("---")
    
    # æ˜ç»†è¡¨
    st.subheader("ğŸ“‹ å·¥æ—¶æ˜ç»†")
    render_detail_table(df, date_range)

if __name__ == "__main__":
    main()
